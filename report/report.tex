\documentclass[english]{scrartcl}
\usepackage{babel}
\usepackage[margin=1.1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{enumitem} % para poder empezar con 0 el enumerate
\usepackage{soul}

\hypersetup{
	pdftitle={APA - Practical Work Report},
	colorlinks=true, % Use colours instead of boxes.
	urlcolor=blue
}

\newcommand\ms[1]{\texttt{#1}}
\newcommand\R[1]{\texttt{#1}}
\soulregister{\ms}{1}
\soulregister{\R}{1}

\begin{document}
\thispagestyle{empty}
\begin{center}

\vspace*{\fill}

{\bf\LARGE APA - Practical Work Report}
\par \vspace{6mm}
{\LARGE FIB - 2012-2013 Q1}

\par 
\par\vspace{3mm}

{\bf 
    Alejandro Fernández Suárez\\
    Marc Sunet Pérez
}

\par\vspace{5mm}
{\bf\LARGE Census Income Classification}
\vspace{3mm}

\vspace*{\fill}

\end{center}

\newpage

\vspace*\fill

\thispagestyle{empty}
\tableofcontents

\vspace*\fill

\newpage
\setcounter{page}{1}
\section{Description of the problem and available data}

The problem consists in creating a model that predicts whether a given individual makes \$50K or more a year. Training and testing data has been obtained from \url{http://archive.ics.uci.edu/ml/datasets/Census+Income}.

Each individual in the data set specifies a set indicators such as age, work class and education, from which the yearly income has to be predicted. Our goal is to make that prediction, to tell which variables the target variable is truly dependent on and to analyse the results. In the process, we test different machine learning algorithms and compare the quality of their outputs.

\section{Data pre-processing}

Our dataset comes from a discrete census information table, meaning that no values come from continuous/noisy sources such as image, sound or video and that therefore no tinkering has to be performed on the input values.

The only transformation we apply to the input is the conversion of categorial fields such as race and sex to numerical values and the conversion of the target variable to a factor. These two steps are needed by all of the classification models that we build, which is why we perform them as part of the pre-processing.

\section{Models}

The problem at hand is a binary classification one and we have therefore chosen appropriate models for this task, namely LDA/QDA, MLP neural networks, logistic regression and SVMs. In the following sections we describe the procedure used to build each of the models.

    \subsection{LDA/QDA}
    
    \subsubsection{Regularization and dataset partitioning for LDA and QDA}
    As we'll see in section \ref{sec:methods:ldaqda}, we use Leave-One-Out Cross Validation to get the best linear and quadratic classification models we 
    can. The data set is partitioned in learning and testing subsets to check the accuracy of the methods without using LOOCV.
    
    \subsubsection{Linear and Quadratic Classification Models}
    \label{sec:methods:ldaqda}
    Both Linear and Quadratic Discriminant Analysis models are validated using
    half of the samples of the original dataset. The half of the data used for training (model creation) is composed by
    randomly selected samples. The second half is composed by the samples not in the training set and it's called the 
    testing set. Both Linear and Quadratic models are analyzed and validated predicting the learning dataset and the test
    dataset. Regularized models are finally obtained using Leave-One-Out Cross Validation, giving place to more robust
    and reliable classifiers.
    
    \subsection{MLP Neural Network}
    \label{sec:methods:nnet}
    We have built two neural network models. The first one uses all the input data, while the second uses only the most
    relevant features of the input, as analyzed previously.
    
    \subsubsection{MLP Neural Network hidden units analysis}
    For the case of the MLP neural network, the non-linear model obtained is validated by just predicting the training set. However, for both models obtained
    (see section \ref{sec:methods:nnet}), we analyze which is the best number of hidden units from 1 up to 10. The results obtained will be shown in detail in
    section \ref{sec:results:nnet}.
    
    \subsection{Logistic Regression}
    An initial model is built from the entire data set. We then find out which variables the target is dependent on and we build a second model using only these variables. This second model is compared against the first one to verify that the variables that have are discarded are indeed irrelevant to predict the target variable.
    
    Using the selected variables only, we then apply k-fold cross-validation for different values of k to obtain a set of different models, as well as leave-one-out cross-validation to obtain a last one.
    
    \subsection{SVM}
    Different SVM models are built from the data set. First, we build linear, polynomial and radial models from the entire data set. Then, we apply 3-fold cross-validation and obtain another set of models for each of the test/trainining partitions. The models are then compared to see which one performs the best.

\section{Results}

    \subsection{Linear and Quadratic Classification Models}
    Given the nature of the problem, linear and quadratic classification models give good enough results because the influence
    of each input parameter is not bound to the values of the rest of parameters. Since there are many different input parameters,
    linear and quadratic models work good at balancing the weight of each input on the final results. This is the accuracy
    obtained for each model and testing set:
    \begin{itemize}
    \item LDA - Resubstitution of the learning data set: ~76\%
    \item LDA - True accuracy using testing set: ~58\%
    \item LDA - Regularized (LOOCV) model: ~77\%
    \item QDA - Resubstitution of the learning data set: ~81\%
    \item QDA - True accuracy using testing set: ~68\%
    \item QDA - Regularized (LOOCV) model: ~82\%
    \end{itemize}
    As we can see, the quadratic methods a fairly better results compared to the linear ones for our problem.
    
    \subsection{MLP Neural Network}\label{sec:results:nnet}
    The non-linear models we get using neural networks don't show special good features due again to the nature of the problem itself.
    As we'll go on, we'll see that our problem can be modelled in a good enough way using linear methods. Thus, non-linear models provide
    good solutions too, but don't show any special qualities with respect to the linear approaches. These are the results obtained for
    our neural networks:
    \begin{itemize}
    \item Using all inputs: The best accuracy obtained is ~77\% with 7 hidden units
    \item Using only the most relevant inputs: The best accuracy obtained is ~79\% with 9 hidden units
    \end{itemize}
    
    \subsection{Logistic Regression}
    Results for the logistic regression models are summarised in table \ref{table:logit-results}.
    
    \begin{table}[h]
    \centering
    \begin{tabular}{l c}
    \textbf{Model} & \textbf{Error rate} \\
    Initial & 123 \\
    Initial (bin) & 123 \\
    Pruned & 123 \\
    Pruned (bin) & 123 \\
    2-fold & 0.2450596 \\
    3-fold & 0.2432385 \\
    4-fold & 0.2439326 \\
    5-fold & 0.2438422 \\
    6-fold & 0.2447852 \\
    \end{tabular}
    \caption{Results for logistic regression models.}
    \label{table:logit-results}
    \end{table}
    
        
    \subsection{SVM}
    The results obtained from the SVM models are the ones shown in table \ref{table:svm-results}.
    
    \begin{table}[h]
    \centering
    \begin{tabular}{l c}
    \textbf{Model} & \textbf{Error rate} \\
    Linear & 0.1848894 \\
	Polynomial & 0.1511978 \\
	Radial & 0.1437654 \\
	Linear-CV1 & 0.1870278 \\
	Polynomial-CV1 & 0.1566243 \\
	Radial-CV1 & 0.1512806 \\
	Linear-CV2 & 0.1851852 \\
	Polynomial-CV2 & 0.1579141 \\
	Radial-CV2 & 0.1517413 \\
	Linear-CV3 & 0.1836359 \\
	Polynomial-CV3 & 0.1612457 \\
	Radial-CV3 & 0.1535059 \\
    \end{tabular}
    \caption{Results obtained from the different SVM models.}
    \label{table:svm-results}
    \end{table}
    
    The models labeled \ms{Linear}, \ms{Polynomial} and \ms{Radial} correspond to the models obtained using leave-one-out cross-validation. The ones labeled \ms{Linear-CVi}, \ms{Polynomial-CVi} and \ms{Radial-CVi} for $i \in \{1,2,3\}$ are the ones obtained using 3-fold cross-validation.
    
    As we can see, even though it seems the input is not linearly separable, it does seem to be close enough, as the differences in error rates between the linear and polynomial models are very tight. Furthermore, it is worth noting that the radial models do not present a significant improvement over the polynomial ones, so we conclude that the input data can be separated both polynomically and linearly, although not without making a few extra errors in the latter case.

\section{Method Comparison}

\section{Final Model and Generalisation Error}

\section{Conclusion}

\end{document}
